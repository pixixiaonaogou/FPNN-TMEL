{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TkAgg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyc\\Desktop\\胸部超声数据集\\Dataset_BUSI\\new_segmodel.py:305: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.W.weight, 0)\n",
      "C:\\Users\\hyc\\Desktop\\胸部超声数据集\\Dataset_BUSI\\new_segmodel.py:306: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.W.bias, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 40237625 Trainable: 40237625\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from segmodel import *\n",
    "from new_segmodel import,non_local_network\n",
    "from loss import *\n",
    "from dataloader import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "import torch.nn.functional as F\n",
    "from rate import *\n",
    "from torch import optim\n",
    "from torchcontrib.optim import SWA\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import lovasz_losses as L\n",
    "torch.cuda.set_device(0)\n",
    "from random import shuffle\n",
    "from tqdm import tqdm_notebook\n",
    "#from HRNet import seg_hrnet\n",
    "#from non_local_model import asymmetric_non_local_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skip = [\"encoder.layer0.bn1.num_batches_tracked\", \"encoder.layer1.0.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.0.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer1.0.downsample.1.num_batches_tracked\", \"encoder.layer1.1.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.1.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.bn2.num_batches_tracked\",\n",
    "                \"encoder.layer1.2.bn3.num_batches_tracked\", \"encoder.layer2.0.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.1.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.bn2.num_batches_tracked\",\n",
    "                \"encoder.layer2.2.bn3.num_batches_tracked\", \"encoder.layer2.3.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer2.3.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.bn2.num_batches_tracked\",\n",
    "                \"encoder.layer3.0.bn3.num_batches_tracked\", \"encoder.layer3.0.downsample.1.num_batches_tracked\",\n",
    "                \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.bn2.num_batches_tracked\",\n",
    "                \"encoder.layer3.1.bn3.num_batches_tracked\", \"encoder.layer3.2.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.2.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.bn2.num_batches_tracked\",\n",
    "                \"encoder.layer3.3.bn3.num_batches_tracked\", \"encoder.layer3.4.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.4.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.bn2.num_batches_tracked\",\n",
    "                \"encoder.layer3.5.bn3.num_batches_tracked\", \"encoder.layer4.0.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.bn1.num_batches_tracked\",\n",
    "                \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.1.bn3.num_batches_tracked\",\n",
    "                \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.bn2.num_batches_tracked\",\n",
    "                \"encoder.layer4.2.bn3.num_batches_tracked\", \"encoder1.bn1.num_batches_tracked\",\n",
    "                \"encoder2.0.bn1.num_batches_tracked\", \"encoder2.0.bn2.num_batches_tracked\",\n",
    "                \"encoder2.0.bn3.num_batches_tracked\", \"encoder2.0.downsample.1.num_batches_tracked\",\n",
    "                \"encoder2.1.bn1.num_batches_tracked\", \"encoder2.1.bn2.num_batches_tracked\",\n",
    "                \"encoder2.1.bn3.num_batches_tracked\", \"encoder2.2.bn1.num_batches_tracked\",\n",
    "                \"encoder2.2.bn2.num_batches_tracked\", \"encoder2.2.bn3.num_batches_tracked\",\n",
    "                \"encoder3.0.bn1.num_batches_tracked\", \"encoder3.0.bn2.num_batches_tracked\",\n",
    "                \"encoder3.0.bn3.num_batches_tracked\", \"encoder3.0.downsample.1.num_batches_tracked\",\n",
    "                \"encoder3.1.bn1.num_batches_tracked\", \"encoder3.1.bn2.num_batches_tracked\",\n",
    "                \"encoder3.1.bn3.num_batches_tracked\", \"encoder3.2.bn1.num_batches_tracked\",\n",
    "                \"encoder3.2.bn2.num_batches_tracked\", \"encoder3.2.bn3.num_batches_tracked\",\n",
    "                \"encoder3.3.bn1.num_batches_tracked\", \"encoder3.3.bn2.num_batches_tracked\",\n",
    "                \"encoder3.3.bn3.num_batches_tracked\", \"encoder4.0.bn1.num_batches_tracked\",\n",
    "                \"encoder4.0.bn2.num_batches_tracked\", \"encoder4.0.bn3.num_batches_tracked\",\n",
    "                \"encoder4.0.downsample.1.num_batches_tracked\", \"encoder4.1.bn1.num_batches_tracked\",\n",
    "                \"encoder4.1.bn2.num_batches_tracked\", \"encoder4.1.bn3.num_batches_tracked\",\n",
    "                \"encoder4.2.bn1.num_batches_tracked\", \"encoder4.2.bn2.num_batches_tracked\",\n",
    "                \"encoder4.2.bn3.num_batches_tracked\", \"encoder4.3.bn1.num_batches_tracked\",\n",
    "                \"encoder4.3.bn2.num_batches_tracked\", \"encoder4.3.bn3.num_batches_tracked\",\n",
    "                \"encoder4.4.bn1.num_batches_tracked\", \"encoder4.4.bn2.num_batches_tracked\",\n",
    "                \"encoder4.4.bn3.num_batches_tracked\", \"encoder4.5.bn1.num_batches_tracked\",\n",
    "                \"encoder4.5.bn2.num_batches_tracked\", \"encoder4.5.bn3.num_batches_tracked\",\n",
    "                \"encoder5.0.bn1.num_batches_tracked\", \"encoder5.0.bn2.num_batches_tracked\",\n",
    "                \"encoder5.0.bn3.num_batches_tracked\", \"encoder5.0.downsample.1.num_batches_tracked\",\n",
    "                \"encoder5.1.bn1.num_batches_tracked\", \"encoder5.1.bn2.num_batches_tracked\",\n",
    "                \"encoder5.1.bn3.num_batches_tracked\", \"encoder5.2.bn1.num_batches_tracked\",\n",
    "                \"encoder5.2.bn2.num_batches_tracked\", \"encoder5.2.bn3.num_batches_tracked\",\n",
    "                \"center.0.bn.num_batches_tracked\", \"center.2.bn.num_batches_tracked\",\n",
    "                \"decoder5.conv1.bn.num_batches_tracked\", \"decoder5.conv2.bn.num_batches_tracked\",\n",
    "                \"decoder5.context.0.context.1.num_batches_tracked\",\n",
    "                \"decoder5.context.0.context.3.stages.0.f_key.1.num_batches_tracked\",\n",
    "                \"decoder5.context.0.context.3.stages.0.f_query.1.num_batches_tracked\",\n",
    "                \"decoder5.context.0.context.3.conv_bn_dropout.1.num_batches_tracked\",\n",
    "                \"decoder5.context.0.conv2.1.num_batches_tracked\", \"decoder5.context.0.conv3.1.num_batches_tracked\",\n",
    "                \"decoder5.context.0.conv4.1.num_batches_tracked\", \"decoder5.context.0.conv5.1.num_batches_tracked\",\n",
    "                \"decoder5.context.0.conv_bn_dropout.1.num_batches_tracked\", \"decoder4.conv1.bn.num_batches_tracked\",\n",
    "                \"decoder4.conv2.bn.num_batches_tracked\", \"decoder4.context.0.context.1.num_batches_tracked\",\n",
    "                \"decoder4.context.0.context.3.stages.0.f_key.1.num_batches_tracked\",\n",
    "                \"decoder4.context.0.context.3.stages.0.f_query.1.num_batches_tracked\",\n",
    "                \"decoder4.context.0.context.3.conv_bn_dropout.1.num_batches_tracked\",\n",
    "                \"decoder4.context.0.conv2.1.num_batches_tracked\", \"decoder4.context.0.conv3.1.num_batches_tracked\",\n",
    "                \"decoder4.context.0.conv4.1.num_batches_tracked\", \"decoder4.context.0.conv5.1.num_batches_tracked\",\n",
    "                \"decoder4.context.0.conv_bn_dropout.1.num_batches_tracked\", \"decoder3.conv1.bn.num_batches_tracked\",\n",
    "                \"decoder3.conv2.bn.num_batches_tracked\", \"decoder3.context.0.context.1.num_batches_tracked\",\n",
    "                \"decoder3.context.0.context.3.stages.0.f_key.1.num_batches_tracked\",\n",
    "                \"decoder3.context.0.context.3.stages.0.f_query.1.num_batches_tracked\",\n",
    "                \"decoder3.context.0.context.3.conv_bn_dropout.1.num_batches_tracked\",\n",
    "                \"decoder3.context.0.conv2.1.num_batches_tracked\", \"decoder3.context.0.conv3.1.num_batches_tracked\",\n",
    "                \"decoder3.context.0.conv4.1.num_batches_tracked\", \"decoder3.context.0.conv5.1.num_batches_tracked\",\n",
    "                \"decoder3.context.0.conv_bn_dropout.1.num_batches_tracked\", \"decoder2.conv1.bn.num_batches_tracked\",\n",
    "                \"decoder2.conv2.bn.num_batches_tracked\", \"decoder2.context.0.context.1.num_batches_tracked\",\n",
    "                \"decoder2.context.0.context.3.stages.0.f_key.1.num_batches_tracked\",\n",
    "                \"decoder2.context.0.context.3.stages.0.f_query.1.num_batches_tracked\",\n",
    "                \"decoder2.context.0.context.3.conv_bn_dropout.1.num_batches_tracked\",\n",
    "                \"decoder2.context.0.conv2.1.num_batches_tracked\", \"decoder2.context.0.conv3.1.num_batches_tracked\",\n",
    "                \"decoder2.context.0.conv4.1.num_batches_tracked\", \"decoder2.context.0.conv5.1.num_batches_tracked\",\n",
    "                \"decoder2.context.0.conv_bn_dropout.1.num_batches_tracked\", \"decoder1.conv1.bn.num_batches_tracked\",\n",
    "                \"decoder1.conv2.bn.num_batches_tracked\", \"decoder1.context.0.context.1.num_batches_tracked\",\n",
    "                \"decoder1.context.0.context.3.stages.0.f_key.1.num_batches_tracked\",\n",
    "                \"decoder1.context.0.context.3.stages.0.f_query.1.num_batches_tracked\",\n",
    "                \"decoder1.context.0.context.3.conv_bn_dropout.1.num_batches_tracked\",\n",
    "                \"decoder1.context.0.conv2.1.num_batches_tracked\", \"decoder1.context.0.conv3.1.num_batches_tracked\",\n",
    "                \"decoder1.context.0.conv4.1.num_batches_tracked\", \"decoder1.context.0.conv5.1.num_batches_tracked\",\n",
    "                \"decoder1.context.0.conv_bn_dropout.1.num_batches_tracked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_old_pretrain_file(net, pretrain_file, skip=[]):\n",
    "    pretrain_state_dict = torch.load(pretrain_file)\n",
    "    state_dict = net.state_dict()\n",
    "    keys = list(state_dict.keys())\n",
    "    for key in keys:\n",
    "        if any(s in key for s in skip):\n",
    "            continue\n",
    "        if  key.startswith('conv1'):\n",
    "        #if 'conv1.' in key:\n",
    "            key0 = key.replace('conv1.','layer0.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "        if 'encoder2.' in key:\n",
    "            key0 = key.replace('encoder2.','layer1.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "        if 'encoder3.' in key:\n",
    "            key0 = key.replace('encoder3.','layer2.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "        if 'encoder4.' in key:\n",
    "            key0 = key.replace('encoder4.','layer3.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "        if 'encoder5.' in key:\n",
    "            key0 = key.replace('encoder5.','layer4.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "    net.load_state_dict(state_dict)\n",
    "    return net\n",
    "\n",
    "def load_pretrain_file(net, pretrain_file, skip=[]):\n",
    "\n",
    "    pretrain_state_dict = torch.load(pretrain_file)\n",
    "    state_dict = net.state_dict()\n",
    "    keys = list(state_dict.keys())\n",
    "    for key in keys:\n",
    "        if any(s in key for s in skip):\n",
    "            continue\n",
    "\n",
    "        state_dict[key] = pretrain_state_dict[key]\n",
    "    net.load_state_dict(state_dict)\n",
    "    return net\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from segmodel import *\n",
    "from new_segmodel import SeResNeXt50Unet,MiniSeResNeXt50Unet\n",
    "from loss import *\n",
    "from dataloader import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "import torch.nn.functional as F\n",
    "from rate import *\n",
    "from torch import optim\n",
    "from torchcontrib.optim import SWA\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import lovasz_losses as L\n",
    "torch.cuda.set_device(0)\n",
    "from util import EPE, getEdge\n",
    "from random import shuffle\n",
    "from tqdm import tqdm_notebook\n",
    "#from torchkeras import summary\n",
    "\n",
    "def load_old_pretrain_file(net, pretrain_file, skip=[]):\n",
    "\n",
    "    pretrain_state_dict = torch.load(pretrain_file)\n",
    "    state_dict = net.state_dict()\n",
    "    keys = list(state_dict.keys())\n",
    "    for key in keys:\n",
    "        if any(s in key for s in skip):\n",
    "            continue\n",
    "\n",
    "        if  key.startswith('conv1'):\n",
    "        #if 'conv1.' in key:\n",
    "            key0 = key.replace('conv1.','layer0.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "\n",
    "        if 'encoder2.' in key:\n",
    "            key0 = key.replace('encoder2.','layer1.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "\n",
    "        if 'encoder3.' in key:\n",
    "            key0 = key.replace('encoder3.','layer2.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "\n",
    "        if 'encoder4.' in key:\n",
    "            key0 = key.replace('encoder4.','layer3.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "\n",
    "        if 'encoder5.' in key:\n",
    "            key0 = key.replace('encoder5.','layer4.')\n",
    "            state_dict[key] = pretrain_state_dict[key0]\n",
    "            continue\n",
    "\n",
    "        #print(key)\n",
    "        #state_dict[key] = pretrain_state_dict[key]\n",
    "    net.load_state_dict(state_dict)\n",
    "    return net\n",
    "\n",
    "def load_pretrain_file(net, pretrain_file, skip=[]):\n",
    "\n",
    "    pretrain_state_dict = torch.load(pretrain_file)\n",
    "    state_dict = net.state_dict()\n",
    "    keys = list(state_dict.keys())\n",
    "    for key in keys:\n",
    "        if any(s in key for s in skip):\n",
    "            continue\n",
    "\n",
    "        state_dict[key] = pretrain_state_dict[key]\n",
    "    net.load_state_dict(state_dict)\n",
    "    return net\n",
    "\n",
    "\n",
    "################## training ###########################################\n",
    "def do_valid( net, batch_size, valid_loader ):\n",
    "\n",
    "    valid_num  = 0\n",
    "    valid_loss = np.zeros(3,np.float32)\n",
    "\n",
    "    predicts = []\n",
    "    truths   = []\n",
    "\n",
    "    for input, truth in valid_loader:\n",
    "        input = input.cuda()\n",
    "        truth = truth.cuda()\n",
    "        with torch.no_grad():\n",
    "            logit = net(input)\n",
    "            prob  = F.sigmoid(logit)\n",
    "            loss  = net.criterion(logit, truth)\n",
    "            dice  = net.metric(logit, truth)\n",
    "\n",
    "        #batch_size\n",
    "        valid_loss += batch_size*np.array(( loss.item(), dice.item(), 0))\n",
    "        valid_num += batch_size\n",
    "\n",
    "        predicts.append(prob.data.cpu().numpy())\n",
    "        truths.append(truth.data.cpu().numpy())\n",
    "\n",
    "    #assert(valid_num == len(valid_loader.sampler))\n",
    "    valid_loss  = valid_loss/valid_num\n",
    "\n",
    "    return valid_loss\n",
    "\n",
    "def run_train():\n",
    "\n",
    "    out_dir = './weight_file/'\n",
    "    initial_checkpoint = None\n",
    "    pretrain_file = None\n",
    "\n",
    "    ## setup-----------------------\n",
    "    os.makedirs(out_dir +'/checkpoint/',exist_ok=True)\n",
    "    os.makedirs(out_dir +'/train/', exist_ok=True)\n",
    "    os.makedirs(out_dir +'/backup/',exist_ok=True)\n",
    "\n",
    "    log = Logger()\n",
    "    log.open(out_dir + '/log.train.txt', mode='w')\n",
    "    log.write('\\n--- [START %s] %s\\n\\n' % ('IDENTIFIER', '-' * 64))\n",
    "    log.write('\\t__file__     = %s\\n' % __file__)\n",
    "    log.write('\\tout_dir      = %s\\n' % out_dir)\n",
    "    log.write('\\n')\n",
    "    log.write('\\t<additional comments> ...  \\n')\n",
    "    log.write('\\t  - 5-scale unet  \\n')\n",
    "    log.write('\\t  - more augmentation \\n')\n",
    "    log.write('\\n')\n",
    "\n",
    "\n",
    "    train_image_dir = './train_img/'\n",
    "    train_mask_dir = './train_gt/'\n",
    "    train_file_list = os.listdir(train_image_dir)\n",
    "    val_image_dir = './val_img/'\n",
    "    val_mask_dir = './val_gt/'\n",
    "    val_file_list = os.listdir(val_image_dir)\n",
    "\n",
    "    ## dataset ----------------------------------------\n",
    "    log.write('** dataset setting **\\n')\n",
    "    \n",
    "    shape = (224,224)\n",
    "    \n",
    "    batch_size = 8\n",
    "    \n",
    "    number_workers = 0\n",
    "    \n",
    "    train_skindataset = SkinDataset(image_dir=train_image_dir,\n",
    "                              mask_dir=train_mask_dir,\n",
    "                              file_list=train_file_list,\n",
    "                              shape=shape,is_test=False)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_skindataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers = number_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True)\n",
    "\n",
    "    val_skindataset = SkinDataset(image_dir=val_image_dir,\n",
    "                              mask_dir=val_mask_dir,\n",
    "                              file_list=val_file_list,\n",
    "                              shape=shape,is_test=False)\n",
    "    \n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        dataset=val_skindataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers = number_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True)\n",
    "\n",
    "    assert (len(train_skindataset) >= batch_size)\n",
    "    log.write('batch_size = %d\\n' % (batch_size))\n",
    "    log.write('\\n')\n",
    "\n",
    "    #net ------------------------------------\n",
    "    log.write('** net settint **\\n')\n",
    "    net = SaltNet().cuda()\n",
    "    net.load_pretrain('./se_resnext50_32x4d-a260b3a4.pth')\n",
    "    #print(net)\n",
    "    if initial_checkpoint is not None:\n",
    "        log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n",
    "        net.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    if pretrain_file is not None:\n",
    "        log.write('\\tpretrain_file = %s\\n' % pretrain_file)\n",
    "        net = load_pretrain_file(net, pretrain_file, skip=['feature', 'logit'])\n",
    "\n",
    "    log.write('%s\\n' % (type(net)))\n",
    "    log.write('\\n')\n",
    "\n",
    "    ## optimizer -------------------------------\n",
    "    num_iters = 300 * 1000\n",
    "    iter_smooth = 20\n",
    "    iter_log = 50\n",
    "    iter_valid = 100\n",
    "    iter_save = [0, num_iters-1] \\\n",
    "        +list(range(0,num_iters,500)) # 1*1000\n",
    "\n",
    "    #-----------------------------------------\n",
    "    if 0: ##freeze\n",
    "        for p in net.feature_net.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "    schduler = None  #LR = StepLR([ (0, 0.01),  (200, 0.001),  (300, -1)])\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                          lr=0.005, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    #opt = SWA(optmizer)\n",
    "    start_iter = 0\n",
    "    start_epoch= 0\n",
    "\n",
    "    if initial_checkpoint is not None:\n",
    "        checkpoint  = torch.load(initial_checkpoint.replace('_model.pth','_optimizer.pth'))\n",
    "        start_iter  = checkpoint['iter' ]\n",
    "        start_epoch = checkpoint['epoch']\n",
    "\n",
    "        rate = get_learning_rate(optimizer)  #load all except learning rate\n",
    "        #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        adjust_learning_rate(optimizer, rate)\n",
    "        pass\n",
    "\n",
    "\n",
    "    ## start training here! ##############################################\n",
    "    log.write('** start training here! **\\n')\n",
    "\n",
    "    #log.write(' samples_per_epoch = %d\\n\\n'%len(train_dataset))\n",
    "    log.write(' rate    iter   epoch   | valid_loss               | train_loss               | batch_loss               |  time          \\n')\n",
    "    log.write('-------------------------------------------------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "    train_loss = np.zeros(6,np.float32)\n",
    "    valid_loss = np.zeros(6,np.float32)\n",
    "    batch_loss = np.zeros(6,np.float32)\n",
    "    rate = 0\n",
    "    iter = 0\n",
    "    i    = 0\n",
    "\n",
    "    start = timer()\n",
    "\n",
    "    while iter<num_iters:\n",
    "\n",
    "        sum_train_loss = np.zeros(6,np.float32)\n",
    "        sum = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for image, mask in train_dataloader:\n",
    "            if 0: #debug  ##--------------------------------------------------------\n",
    "                image = image.cpu().data.numpy().squeeze()\n",
    "                mask = mask.cpu().data.numpy().squeeze()\n",
    "\n",
    "                batch_size = len(index)\n",
    "                #print(image.shape)\n",
    "                #print(mask.shape)\n",
    "\n",
    "                #for b in range(batch_size):\n",
    "                ##---------------------------------------\n",
    "\n",
    "            len_train_dataset = len(train_dataloader)\n",
    "            iter = i + start_iter\n",
    "            epoch = (iter - start)*batch_size/len_train_dataset + start_epoch\n",
    "            num_samples = epoch*len_train_dataset\n",
    "\n",
    "            if iter % iter_valid == 0:\n",
    "                net.set_mode('valid')\n",
    "                val_loss = do_valid(net,batch_size,val_dataloader)\n",
    "                net.set_mode('train')\n",
    "\n",
    "                print('\\r',end='',flush=True)\n",
    "                log.write('%0.4f  %5.1f  %6.1f  |  %0.3f  %0.3f  (%0.3f) |  %0.3f  %0.3f  |  %0.3f  %0.3f  | %s \\n' % ( \\\n",
    "                    rate, iter / 1000, epoch,\n",
    "                    valid_loss[0], valid_loss[1], valid_loss[2],\n",
    "                    train_loss[0], train_loss[1],\n",
    "                    batch_loss[0], batch_loss[1],\n",
    "                    str((timer() - start)/60)+ 'min'))\n",
    "                time.sleep(0.01)\n",
    "\n",
    "            if iter in iter_save:\n",
    "                torch.save(net.state_dict(),out_dir +'/checkpoint/%08d_model.pth'%(iter))\n",
    "                torch.save({\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'iter'     : iter,\n",
    "                    'epoch'    : epoch,\n",
    "                }, out_dir +'/checkpoint/%08d_optimizer.pth'%(iter))\n",
    "                pass\n",
    "\n",
    "            #one iteration update ----------------------\n",
    "            #net.seg_mode('train',is_freeze_bn=True)\n",
    "\n",
    "            net.set_mode('train')\n",
    "            image = image.cuda()\n",
    "            mask  = mask.cuda()\n",
    "\n",
    "            logit = net(image)\n",
    "            loss  = net.criterion(logit, mask)\n",
    "            dice  = net.metric(logit, mask)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #torch.nn.utils.clip_grad_norm(net.parameters(),1)\n",
    "\n",
    "            # print statistics ----------------\n",
    "            batch_loss = np.array((\n",
    "                loss.item(),\n",
    "                dice.item(),0,0,0,0,))\n",
    "\n",
    "            sum_train_loss += batch_loss\n",
    "            sum += 1\n",
    "            if iter%iter_smooth == 0:\n",
    "                train_loss = sum_train_loss/sum\n",
    "                sum_train_loss = np.zeros(6,np.float32)\n",
    "                sum = 0\n",
    "\n",
    "\n",
    "            print('\\r%0.4f  %5.1f  %6.1f  |  %0.3f  %0.3f  (%0.3f) |  %0.3f  %0.3f  |  %0.3f  %0.3f  | %s ' % (\\\n",
    "                         rate, iter/1000, epoch,\n",
    "                         valid_loss[0], valid_loss[1], valid_loss[2],\n",
    "                         train_loss[0], train_loss[1],\n",
    "                         batch_loss[0], batch_loss[1],\n",
    "                         str((timer() - start)/60)+'min'), end='',flush=True)\n",
    "            i=i+1\n",
    "\n",
    "\n",
    "            #<debug> ===================================================================\n",
    "            if 0:\n",
    "            #if iter%200==0:\n",
    "                #voxel, aux, query, link, truth, cache = make_valid_batch(valid_dataset.dataset, batch_size=2)\n",
    "\n",
    "                net.set_mode('test')#\n",
    "                with torch.no_grad():\n",
    "                    logit = net(input)\n",
    "                    prob  = F.sigmoid(logit)\n",
    "                    loss  = net.criterion(logit, truth)\n",
    "                    dice  = net.metric(logit, truth)\n",
    "\n",
    "                    if 0:\n",
    "                        loss  = net.criterion(logit, truth)\n",
    "                        accuracy,hit_rate,precision_rate = net.metric(logit, truth)\n",
    "                        valid_loss[0] = loss.item()\n",
    "                        valid_loss[1] = accuracy.item()\n",
    "                        valid_loss[2] = hit_rate.item()\n",
    "                        valid_loss[3] = precision_rate.item()\n",
    "\n",
    "\n",
    "\n",
    "                #show only b in batch ---\n",
    "                b = 1\n",
    "                prob   = prob.data.cpu().numpy()[b].squeeze()\n",
    "                truth  = truth.data.cpu().numpy()[b].squeeze()\n",
    "                input  = input.data.cpu().numpy()[b].squeeze()\n",
    "\n",
    "                all = np.hstack([input,truth,prob])\n",
    "                image_show_norm('all',all,max=1,resize=3)\n",
    "                cv2.waitKey(100)\n",
    "\n",
    "                net.set_mode('train')\n",
    "            #<debug> ===================================================================\n",
    "\n",
    "\n",
    "        pass  #-- end of one data loader --\n",
    "    pass #-- end of all iterations --\n",
    "\n",
    "\n",
    "    if 1: #save last\n",
    "        torch.save(net.state_dict(),out_dir +'/checkpoint/%d_model.pth'%(i))\n",
    "        torch.save({\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'iter'     : i,\n",
    "            'epoch'    : epoch,\n",
    "        }, out_dir +'/checkpoint/%d_optimizer.pth'%(i))\n",
    "\n",
    "    log.write('\\n')\n",
    "    log.close()\n",
    "\n",
    "\n",
    "class Logger:\n",
    "\n",
    "    def __int__(self):\n",
    "        super(Logger, self).__int__()\n",
    "\n",
    "    def open(self,name,mode):\n",
    "        self.txt = open(name,mode=mode)\n",
    "\n",
    "    def write(self,str_):\n",
    "        self.txt.write(str_)\n",
    "        print(str_)\n",
    "\n",
    "    def close(self):\n",
    "        self.txt.close()\n",
    "\n",
    "def adjust_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def get_list_from_txt(txt_dir):\n",
    "    img_list = []\n",
    "\n",
    "    with open(txt_dir) as f:\n",
    "        for i in f:\n",
    "            img_list.append(i.strip('\\n').strip('\\t'))\n",
    "    \n",
    "    return img_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from random import shuffle\n",
    "data_dir = 'D:/ultrasound image/胸部超声数据集/Dataset_BUSI/Dataset_BUSI_with_GT/total/'\n",
    "total_image_list  = [] \n",
    "\n",
    "for name in os.listdir(data_dir):\n",
    "    if 'mask' in name: # remove the ground truth name\n",
    "        continue\n",
    "    total_image_list.append(name)\n",
    "\n",
    "shuffle(total_image_list)\n",
    "total_image_num = len(total_image_list)\n",
    "train_image_num = 562 # about 0.7 * total_image_num\n",
    "val_image_num   = 86  # about 0.1 * total_image_num\n",
    "test_image_num  = 132 # about 0.2 * total_image_num\n",
    "\n",
    "train_image_list = total_image_list[:train_image_num]\n",
    "val_image_list   = total_image_list[train_image_num:train_image_num+val_image_num]\n",
    "test_image_list  = total_image_list[train_image_num+val_image_num:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_image_dir = './Dataset_BUSI_with_GT/total/'\n",
    "num_class = 1\n",
    "number_workers = 2\n",
    "#epochs = 20\n",
    "thresh = 0.5\n",
    "shape = (224,224)\n",
    "batch_size = 8\n",
    "multi_class = False\n",
    "if num_class > 1:\n",
    "    multi_class = True\n",
    "#Building Dasaset\n",
    "\n",
    "train_skindataset = SkinDataset(image_dir=total_image_dir,\n",
    "                          mask_dir=total_image_dir,\n",
    "                          file_list=train_image_list+train_image_list,\n",
    "                          shape=shape,is_test=False,num_class=num_class,is_mask=False)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_skindataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers = number_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True)\n",
    "\n",
    "val_skindataset = SkinDataset(image_dir=total_image_dir,\n",
    "                          mask_dir=total_image_dir,\n",
    "                          file_list=val_image_list,\n",
    "                          shape=shape,is_test=True,num_class=num_class,is_mask=False)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_skindataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers = number_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameter_number(net):\n",
    "    total_num = sum(p.numel() for p in net.parameters())\n",
    "    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print('Total: {}'.format(total_num), 'Trainable: {}'.format(trainable_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_mixup(input1, input2, lambda1):\n",
    "    lambda2 = torch.from_numpy(np.array(1.)) - lambda1\n",
    "    mixup_input = input1.mul(lambda1) + input2.mul(lambda2)\n",
    "    return mixup_input\n",
    "\n",
    "def make_one_hot(labels):\n",
    "\ttarget = torch.eye(1)[labels]\n",
    "\tgt_1_hot = target.permute(0, 3, 1, 2).float().to(0)\n",
    "\treturn gt_1_hot\n",
    "\n",
    "def label_mixup(labels1, labels2, lambda1):\n",
    "\tlambda2 = torch.from_numpy(np.array(1.))-lambda1\n",
    "\tmixup_label = labels1.mul(lambda1)+ labels2.mul(lambda2)\n",
    "\n",
    "\tmixup_label_margin = 0.4\n",
    "\tmixup_label = (mixup_label > mixup_label_margin) * 1\n",
    "\treturn mixup_label.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_my_train(out_dir,shape,swa_epoch,pretrained,weight_file,batch_size,epochs,\n",
    "                 model_name,edge_model,num_class,dataset,NFN_model,SKN_module,kernel_three):\n",
    "    #out_dir = './weight_file_1/'\n",
    "    initial_checkpoint = None\n",
    "    pretrain_file = None\n",
    "\n",
    "    ## setup-----------------------\n",
    "    os.makedirs(out_dir +'/checkpoint/',exist_ok=True)\n",
    "    os.makedirs(out_dir +'/train/', exist_ok=True)\n",
    "    os.makedirs(out_dir +'/backup/',exist_ok=True)\n",
    "\n",
    "    log = Logger()\n",
    "    log.open(out_dir + '/log.train_skinlesion.txt', mode='w')\n",
    "    log.write('\\n--- [START %s] %s\\n\\n' % ('IDENTIFIER', '-' * 64))\n",
    "    #log.write('\\t__file__     = %s\\n' % __file__)\n",
    "    log.write('\\tout_dir      = %s\\n' % out_dir)\n",
    "    log.write('\\n')\n",
    "    log.write('\\t<additional comments> ...  \\n')\n",
    "    log.write('\\t  - 5-scale unet  \\n')\n",
    "    log.write('\\t  - more augmentation \\n')\n",
    "    log.write('\\n')\n",
    "\n",
    "    total_image_dir = './Dataset_BUSI_with_GT/total/'\n",
    "    if dataset == 'new':\n",
    "        total_image_dir = './Dataset_BUSI_with_GT/total_new/'\n",
    "    \n",
    "    print(total_image_dir)\n",
    "    number_workers = 2\n",
    "\n",
    "    thresh = 0.5\n",
    "    \n",
    "    multi_class = False\n",
    "    if num_class > 1:\n",
    "        multi_class = True\n",
    "    #Building Dasaset\n",
    "    \n",
    "    train_skindataset = SkinDataset(image_dir=total_image_dir,\n",
    "                              mask_dir=total_image_dir,\n",
    "                              file_list=train_image_list,\n",
    "                              shape=shape,is_test=False,num_class=num_class,is_mask=False)\n",
    "\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_skindataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers = number_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True)\n",
    "   \n",
    "    val_skindataset = SkinDataset(image_dir=total_image_dir,\n",
    "                              mask_dir=total_image_dir,\n",
    "                              file_list=val_image_list,\n",
    "                              shape=shape,is_test=True,num_class=num_class,is_mask=False)\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        dataset=val_skindataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers = number_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True)\n",
    "\n",
    "    #Build the model------------------------------\n",
    "\n",
    "    if model_name == 'non_local':\n",
    "        log.write('Building non_local Model........')\n",
    "        net = non_local_network().cuda()\n",
    "      \n",
    "    get_parameter_number(net)\n",
    "    \n",
    "    try:\n",
    "        encoder_weight_file = 'se_resnext50_32x4d-a260b3a4.pth'\n",
    "        net.load_pretrain(encoder_weight_file)\n",
    "    except:\n",
    "        pass\n",
    "    #---------------------------------------------\n",
    "    if pretrained:\n",
    "        net.load_state_dict(torch.load(weight_file))\n",
    "\n",
    "    #bulid the optimizer\n",
    "    schduler = None  #LR = StepLR([ (0, 0.01),  (200, 0.001),  (300, -1)])\n",
    "    lr = 0.005\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                          lr=lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "   # optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "    #                      lr=lr,)\n",
    "\n",
    "    opt = SWA(optimizer)\n",
    "\n",
    "    # start training here! #################################################\n",
    "    log.write('** start training here! **\\n')\n",
    "    best_dice = 0\n",
    "    best_loss = 1\n",
    "    best_jac = 0\n",
    "    \n",
    "    cosine_learning_schule = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        cos_inner = np.pi * (epoch % epochs)  # t - 1 is used when t has 1-based indexing.\n",
    "        cos_inner /= epochs\n",
    "        cos_out = np.cos(cos_inner) + 1\n",
    "        final_lr = float(lr / 2 * cos_out)\n",
    "        cosine_learning_schule.append(final_lr)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        swa_lr = cosine_learning_schule[epoch]\n",
    "        adjust_learning_rate(opt,swa_lr)\n",
    "        # train mode\n",
    "        net.set_mode('train')\n",
    "        train_loss = 0\n",
    "        train_dice = 0  #focal_loss\n",
    "        train_Jac  = 0\n",
    "        \n",
    "        train_mixed_loss = 0\n",
    "        train_mixed_dice = 0\n",
    "        train_mixed_jac  = 0\n",
    "        for index, (image, mask) in enumerate(train_dataloader):\n",
    "            image = image.cuda()\n",
    "            mask  = mask.cuda()\n",
    "            logit = net(image)\n",
    "            loss = net.criterion(logit, mask) \n",
    "            dice,Jac = net.metric(logit,mask,thresh)        \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_dice += dice.item()\n",
    "            train_Jac  += Jac.item()\n",
    "\n",
    "        train_loss = train_loss / (index+1)\n",
    "        train_dice = train_dice / (index+1)\n",
    "        train_Jac  = train_Jac  / (index+1)\n",
    "\n",
    "        log.write('epoch: {}, Train Loss: {:.4f}, Train Dice: {:.4f}, Train Jac: {:.4f}\\n'.format(epoch,train_loss,train_dice,train_Jac))\n",
    "   #     log.write('Mixed epoch: {}, Train Loss: {:.4f}, Train Dice: {:.4f}, Train Jac: {:.4f}\\n'.format(epoch,train_mixed_loss,train_mixed_dice,train_mixed_jac))\n",
    "\n",
    "        #validation mode\n",
    "        net.set_mode('valid')\n",
    "        val_loss = 0\n",
    "        val_dice = 0\n",
    "        val_Jac = 0\n",
    "        for index, (image, mask) in enumerate(val_dataloader):\n",
    "            image = image.cuda()\n",
    "            #image_pred = image_pred.cuda()\n",
    "            mask = mask.cuda()\n",
    "            #in_mask = in_mask.cuda()\n",
    "            with torch.no_grad():\n",
    "\n",
    "                        logit = net(image)\n",
    "                        \n",
    "                        preds = F.sigmoid(logit)\n",
    "                        uncertainty = -1.0*torch.sum(preds*torch.log(preds + 1e-6), dim=1, keepdim=True)\n",
    "                        ua_logit = uncertainty*logit\n",
    "                        \n",
    "                        loss = net.criterion(logit, mask) + 0.5*net.criterion(ua_logit,mask)\n",
    "\n",
    "\n",
    "                        dice,Jac = net.metric(logit,mask,thresh)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_dice += dice.item()\n",
    "            val_Jac  += Jac.item()\n",
    "\n",
    "        val_loss = val_loss / (index + 1)\n",
    "        val_dice = val_dice / (index + 1)\n",
    "        val_Jac  = val_Jac  / (index + 1)\n",
    "\n",
    "        log.write('epoch: {}, Valid Loss: {:.4f}, Valid Dice: {:.4f}, Valid Jac: {:.4f}\\n'.format(epoch, val_loss, val_dice,val_Jac))\n",
    "\n",
    "\n",
    "        #save the model's weight\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            torch.save(net.state_dict(),out_dir +'/checkpoint/{}_model.pth'.format('best_dice'))\n",
    "            log.write('Current Best Dice is {}'.format(best_dice))\n",
    "            #print('Current Best Dice is {}'.format(best_dice))\n",
    "#        if val_loss < best_loss:\n",
    "#            best_loss = val_loss\n",
    "#            torch.save(net.state_dict(),out_dir +'/checkpoint/{}_model.pth'.format('best_loss'))\n",
    "#            log.write('Current Best Loss is {}'.format(best_loss))\n",
    "            #print('Current Best Loss is {}'.format(best_loss))\n",
    "#        if val_Jac > best_jac:\n",
    "#            best_jac = val_Jac\n",
    "#            torch.save(net.state_dict(),out_dir +'/checkpoint/{}_model.pth'.format('best_jac'))\n",
    "#            log.write('Current Best JAC is {}'.format(best_jac))\n",
    "            #print('Current Best Loss is {}'.format(best_loss))\n",
    "        if epoch > (epochs-swa_epoch) and epoch % 1 == 0:\n",
    "            opt.update_swa()\n",
    "            log.write('SWA Epoch: {}'.format(epoch))\n",
    "            #torch.save(net.state_dict(),out_dir +'/checkpoint/{}_model.pth'.format(epoch))\n",
    "            #print('SWA Epoch: {}'.format(epoch))\n",
    "        \n",
    "    \n",
    "    end_time = time.time()\n",
    "    opt.swap_swa_sgd()\n",
    "    torch.save(net.state_dict(),out_dir +'/checkpoint/{}_model.pth'.format('SWA'))\n",
    "    total_time = (end_time - start_time)/3600\n",
    "    log.write(\"Total time: {}h\".format(total_time))           \n",
    "    log.close()\n",
    "    end_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    shape = (128,128)\n",
    "    mode = 'train'\n",
    "    swa_epoch = 5\n",
    "    pretrained = False\n",
    "    weight_file = './'\n",
    "    batch_size = 8\n",
    "    epochs = 100\n",
    "    dataset = 'old'\n",
    "    model_name = 'non_local'\n",
    "    out_dir = '{}_model_{}'.format(model_name,dataset)\n",
    "    edge_model = False\n",
    "    num_class = 1\n",
    "    dataset_name = 'aiji'\n",
    "    NFN_mode = False\n",
    "    SKN_module = False\n",
    "    kernel_three = False\n",
    "    if mode == 'train':          \n",
    "        weight_file = None\n",
    "        run_my_train(out_dir,shape,swa_epoch,pretrained,weight_file,\n",
    "                     batch_size,epochs,model_name,edge_model,num_class,dataset,NFN_mode,SKN_module,kernel_three)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    shape = (128,128)\n",
    "    mode = 'train'\n",
    "    swa_epoch = 5\n",
    "    pretrained = False\n",
    "    weight_file = './'\n",
    "    batch_size = 8\n",
    "    epochs = 100\n",
    "    dataset = 'new'\n",
    "    model_name = 'non_local'\n",
    "    out_dir = '{}_model_{}'.format(model_name,dataset)\n",
    "    edge_model = False\n",
    "    num_class = 1\n",
    "    dataset_name = 'aiji'\n",
    "    NFN_mode = False\n",
    "    SKN_module = False\n",
    "    kernel_three = False\n",
    "    if mode == 'train':          \n",
    "        weight_file = None\n",
    "        run_my_train(out_dir,shape,swa_epoch,pretrained,weight_file,\n",
    "                     batch_size,epochs,model_name,edge_model,num_class,dataset,NFN_mode,SKN_module,kernel_three)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_my_test(test_img_path,weight_file,output_dir,shape,model_name,edge_model,\n",
    "                num_class=1,uncertainty_path='./uncertainty/',multi_class=False,NFN_model=False,TTA=False,size=224,jigsaw=False,\n",
    "                SKN_module=False,kernel_three=False,dataset_name=None):\n",
    "\n",
    "    if model_name == 'non_local':\n",
    "       # log.write('Building non_local Model........')\n",
    "        net = non_local_network().cuda()\n",
    "\n",
    "    get_parameter_number(net)\n",
    "    os.makedirs(uncertainty_path,exist_ok=True)\n",
    "    os.makedirs(output_dir,exist_ok=True)\n",
    "    net.set_mode('valid')\n",
    "    print('Loading Weight File: {}'.format(weight_file))\n",
    "\n",
    "    try:\n",
    "        net.load_state_dict(torch.load(weight_file))\n",
    "\n",
    "    except:\n",
    "\n",
    "        load_pretrain_file(net, weight_file, skip)\n",
    "\n",
    "    print('Done!')\n",
    "    print('Start Testing')\n",
    "    #start_time = time.time()\n",
    "    \n",
    "    for img_name in tqdm(test_image_list):\n",
    "        img = cv2.imread(test_img_path+img_name)\n",
    "        img = cv2.resize(img,shape)\n",
    "\n",
    "        if TTA:            \n",
    "            img_hf = cv2.flip(img, 0)\n",
    "            img_vf = cv2.flip(img, 1)\n",
    "            img_vhf = cv2.flip(img, -1)\n",
    "            img_total = np.array([img, img_hf, img_vf,img_vhf])\n",
    "\n",
    "\n",
    "            img_tensor = torch.from_numpy(np.transpose(img_total,[0,3,1,2]).astype(np.float32))/255\n",
    "\n",
    "            if edge_model:\n",
    "                logit,in_logit = net(torch.autograd.Variable(img_tensor).cuda())\n",
    "                logit = (logit+1-in_logit)/2\n",
    "            else:\n",
    "                logit = net(torch.autograd.Variable(img_tensor).cuda())\n",
    "\n",
    "            index = 0\n",
    "            pred_total = F.sigmoid(logit)\n",
    "            pred_total = pred_total.cpu().data.numpy()\n",
    "\n",
    "\n",
    "            pred_0_0 = pred_total[0,index,:,:]\n",
    "            pred_1_0 = cv2.flip(pred_total[1,index,:,:],0)\n",
    "            pred_2_0 = cv2.flip(pred_total[2, index, :, :], 1)\n",
    "            pred_3_0 = cv2.flip(pred_total[3, index, :, :], -1)\n",
    "\n",
    "            pred_0 = pred_0_0\n",
    "            pred_1 = pred_1_0\n",
    "            pred_2 = pred_2_0\n",
    "            pred_3 = pred_3_0\n",
    "\n",
    "            final_pred = 255*(pred_0+pred_1+pred_2+pred_3)/4\n",
    "\n",
    "        else:\n",
    "            img_total = np.expand_dims(img,0)\n",
    "            img_tensor = torch.from_numpy(np.transpose(img_total,[0,3,1,2]).astype(np.float32))/255\n",
    "\n",
    "            if edge_model:\n",
    "                logit,in_logit = net(torch.autograd.Variable(img_tensor).cuda())\n",
    "                logit = (logit+1-in_logit)/2\n",
    "               # preds = F.sigmoid(logit)\n",
    "               # uncertainty = -1.0*torch.sum(preds*torch.log(preds + 1e-6), dim=1, keepdim=True)\n",
    "               # ua_logit = uncertainty*logit\n",
    "                        \n",
    "\n",
    "            else:\n",
    "                logit = net(torch.autograd.Variable(img_tensor).cuda())  \n",
    "               # preds = F.sigmoid(logit)\n",
    "               # uncertainty = -1.0*torch.sum(preds*torch.log(preds + 1e-6), dim=1, keepdim=True)\n",
    "              #  ua_logit = uncertainty*logit\n",
    "                        \n",
    "            #logit = ua_logit\n",
    "            \n",
    "            index = 0\n",
    "            pred_total = F.sigmoid(logit)\n",
    "            pred_total = pred_total.cpu().data.numpy()\n",
    "            \n",
    "            final_pred = pred_total[0,index,:,:]*255\n",
    "\n",
    "\n",
    "        cv2.imwrite(output_dir+img_name,final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
